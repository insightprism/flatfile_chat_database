{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flatfile Chat Database - Interactive Demo\n",
        "\n",
        "Welcome to the comprehensive demo of the Flatfile Chat Database System! This notebook will walk you through all the key features of this file-based storage solution for AI chat applications.\n",
        "\n",
        "## What you'll learn:\n",
        "- \ud83d\udcbe **Chat Storage**: Store messages, sessions, and user profiles\n",
        "- \ud83d\udcc4 **Document Processing**: Add documents and create embeddings\n",
        "- \ud83d\udd0d **Vector Search**: Semantic similarity search\n",
        "- \ud83d\udd0e **Advanced Search**: Text-based search with filters\n",
        "- \u2699\ufe0f **Configuration**: Both legacy and new architecture\n",
        "- \ud83e\udde0 **PrismMind Integration**: Enhanced document processing\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Added PrismMind path: /home/markly2/prismmind\n",
            "\u2705 All imports successful\\!\n",
            "\ud83d\udcc1 Working directory: /home/markly2/claude_code/flatfile_chat_database_v2/demo\n"
          ]
        }
      ],
      "source": "import sys\nimport os\nfrom pathlib import Path\nimport asyncio\nfrom datetime import datetime\nimport json\n\n# Add parent directory to path to import the flatfile database\nsys.path.append('..')\n\n# Add PrismMind directory to path (if available)\nprismmind_path = '/home/markly2/prismmind'\nif os.path.exists(prismmind_path):\n    sys.path.append(prismmind_path)\n    print(f\"\u2705 Added PrismMind path: {prismmind_path}\")\nelse:\n    print(f\"\u26a0\ufe0f PrismMind not found at: {prismmind_path}\")\n\n# Import the main components - NO LEGACY ADAPTER\nfrom ff_storage_manager import FFStorageManager\nfrom ff_class_configs.ff_configuration_manager_config import FFConfigurationManagerConfigDTO, load_config\nfrom ff_class_configs.ff_chat_entities_config import (\n    FFMessageDTO, FFSessionDTO, FFUserProfileDTO, MessageRole\n)\nfrom ff_search_manager import FFSearchManager, FFSearchQueryDTO\nfrom ff_vector_storage_manager import FFVectorStorageManager\nfrom ff_document_processing_manager import FFDocumentProcessingManager\n\nprint(\"\u2705 All imports successful\\!\")\nprint(f\"\ud83d\udcc1 Working directory: {os.getcwd()}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration Setup\n",
        "\n",
        "Let's configure the database for our demo. We'll use a temporary directory to avoid interfering with any existing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udccd Demo data will be stored in: demo_data\n",
            "\ud83d\udd12 File locking enabled: True\n",
            "\ud83d\udcca Compression enabled: False\n"
          ]
        }
      ],
      "source": [
        "# Create a demo configuration using the new configuration system\n",
        "demo_data_path = Path(\"./demo_data\")\n",
        "demo_data_path.mkdir(exist_ok=True)\n",
        "\n",
        "# Initialize configuration using the new system\n",
        "config = FFConfigurationManagerConfigDTO()\n",
        "config.storage.base_path = str(demo_data_path)\n",
        "config.storage.enable_compression = False  # Disable for easier inspection\n",
        "config.locking.enable_file_locking = True\n",
        "\n",
        "print(f\"\ud83d\udccd Demo data will be stored in: {config.storage.base_path}\")\n",
        "print(f\"\ud83d\udd12 File locking enabled: {config.locking.enable_file_locking}\")\n",
        "print(f\"\ud83d\udcca Compression enabled: {config.storage.enable_compression}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Storage Manager\n",
        "\n",
        "The `FFStorageManager` is the main interface for all database operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 FFStorageManager initialized successfully!\n",
            "\ud83c\udfe0 Base path: demo_data\n",
            "\ud83d\udd27 Backend type: FFFlatfileStorageBackend\n"
          ]
        }
      ],
      "source": [
        "# Initialize the storage manager\n",
        "storage_manager = FFStorageManager(config)\n",
        "\n",
        "print(\"\u2705 FFStorageManager initialized successfully!\")\n",
        "print(f\"\ud83c\udfe0 Base path: {storage_manager.config.storage.base_path}\")\n",
        "print(f\"\ud83d\udd27 Backend type: {type(storage_manager.backend).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. User Management\n",
        "\n",
        "Let's create some demo users and profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udc64 Created user: Alice Johnson (alice)\n",
            "\ud83d\udc64 Created user: Bob Smith (bob)\n",
            "\n",
            "\u2705 All users created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create demo users with updated DTO classes\n",
        "users = [\n",
        "    {\n",
        "        \"user_id\": \"alice\",\n",
        "        \"profile\": FFUserProfileDTO(\n",
        "            user_id=\"alice\",\n",
        "            username=\"Alice Johnson\",\n",
        "            preferences={\"theme\": \"dark\", \"language\": \"en\"},\n",
        "            metadata={\"role\": \"data_scientist\", \"department\": \"AI Research\"}\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"user_id\": \"bob\",\n",
        "        \"profile\": FFUserProfileDTO(\n",
        "            user_id=\"bob\",\n",
        "            username=\"Bob Smith\",\n",
        "            preferences={\"theme\": \"light\", \"language\": \"en\"},\n",
        "            metadata={\"role\": \"developer\", \"department\": \"Engineering\"}\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "# Store user profiles\n",
        "for user in users:\n",
        "    await storage_manager.store_user_profile(user[\"profile\"])\n",
        "    print(f\"\ud83d\udc64 Created user: {user['profile'].username} ({user['user_id']})\")\n",
        "\n",
        "print(\"\\n\u2705 All users created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Chat Sessions and Messages\n",
        "\n",
        "Now let's create some chat sessions and add messages to demonstrate the core functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udcac Created session: AI Research Discussion\n",
            "\ud83c\udd94 Session ID: chat_session_20250731_173607_102321\n",
            "\ud83d\udcc5 Created at: 2025-07-31T17:36:07.102328\n"
          ]
        }
      ],
      "source": [
        "# Create a chat session for Alice\n",
        "alice_session_id = await storage_manager.create_session(\n",
        "    user_id=\"alice\",\n",
        "    title=\"AI Research Discussion\"\n",
        ")\n",
        "alice_session = await storage_manager.get_session(\"alice\", alice_session_id)\n",
        "\n",
        "\n",
        "print(f\"\ud83d\udcac Created session: {alice_session.title}\")\n",
        "print(f\"\ud83c\udd94 Session ID: {alice_session.session_id}\")\n",
        "print(f\"\ud83d\udcc5 Created at: {alice_session.created_at}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Document Processing and RAG Pipeline\n",
        "\n",
        "Let's add some documents to our session and process them for semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "FFDocumentDTO.__init__() got an unexpected keyword argument 'content'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m stored_docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_data \u001b[38;5;129;01min\u001b[39;00m sample_documents:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Create document object\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     document \u001b[38;5;241m=\u001b[39m FFDocumentDTO(\n\u001b[1;32m     59\u001b[0m         filename\u001b[38;5;241m=\u001b[39mdoc_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     60\u001b[0m         content\u001b[38;5;241m=\u001b[39mdoc_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     61\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmachine_learning\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Store document\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m storage_manager\u001b[38;5;241m.\u001b[39mstore_document(\n\u001b[1;32m     66\u001b[0m         alice_session\u001b[38;5;241m.\u001b[39msession_id, \n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     68\u001b[0m         document\n\u001b[1;32m     69\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: FFDocumentDTO.__init__() got an unexpected keyword argument 'content'"
          ]
        }
      ],
      "source": "# Create sample documents and store them directly\nsample_documents = [\n    {\n        \"filename\": \"machine_learning_guide.md\",\n        \"content\": \"\"\"# Machine Learning Guide\n\n## Data Preprocessing\nData preprocessing is a crucial step in machine learning that involves cleaning and transforming raw data into a format suitable for modeling.\n\n### Handling Missing Values\n- **Numerical data**: Use mean, median, or mode imputation\n- **Categorical data**: Use most frequent category or create a separate 'missing' category\n- **Advanced methods**: KNN imputation, iterative imputation\n\n### Feature Scaling\nFeature scaling ensures all features contribute equally to the model:\n- **StandardScaler**: Scales features to have mean=0 and std=1\n- **MinMaxScaler**: Scales features to a fixed range (usually 0-1)\n- **RobustScaler**: Uses median and IQR, robust to outliers\n\n### Encoding Categorical Variables\n- **One-hot encoding**: Creates binary columns for each category\n- **Label encoding**: Assigns numerical values to categories\n- **Target encoding**: Uses target variable statistics\n\"\"\"\n    },\n    {\n        \"filename\": \"deep_learning_basics.md\",\n        \"content\": \"\"\"# Deep Learning Basics\n\n## Neural Networks\nNeural networks are computing systems inspired by biological neural networks. They consist of layers of interconnected nodes (neurons).\n\n### Architecture Components\n- **Input Layer**: Receives the input data\n- **Hidden Layers**: Process the data through weighted connections\n- **Output Layer**: Produces the final prediction\n\n### Activation Functions\n- **ReLU**: Rectified Linear Unit, most commonly used\n- **Sigmoid**: Outputs values between 0 and 1\n- **Tanh**: Outputs values between -1 and 1\n- **Softmax**: Used in multi-class classification\n\n### Training Process\n1. **Forward Pass**: Input data flows through the network\n2. **Loss Calculation**: Compare prediction with actual target\n3. **Backward Pass**: Calculate gradients using backpropagation\n4. **Weight Update**: Adjust weights using optimization algorithm\n\"\"\"\n    }\n]\n\n# Store documents using the correct save_document method\nstored_docs = []\nfor doc_data in sample_documents:\n    # Use save_document method with correct parameters\n    doc_id = await storage_manager.save_document(\n        user_id=\"alice\",\n        session_id=alice_session.session_id,\n        filename=doc_data[\"filename\"],\n        content=doc_data[\"content\"].encode('utf-8'),  # Convert to bytes\n        metadata={\"type\": \"markdown\", \"topic\": \"machine_learning\"}\n    )\n    \n    # Store doc_id and filename for later reference\n    stored_docs.append((doc_id, doc_data[\"filename\"]))\n    print(f\"\ud83d\udcc4 Stored document: {doc_data['filename']} (ID: {doc_id})\")\n\nprint(\"\n\u2705 All documents stored successfully\\!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Vector Storage and Embeddings\n",
        "\n",
        "Let's process our documents to create embeddings for semantic search. Note: This demo uses mock embeddings for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize document pipeline\n",
        "doc_pipeline = FFDocumentProcessingManager(config)\n",
        "\n",
        "print(\"\ud83e\udde0 FFDocumentProcessingManager initialized\")\n",
        "print(f\"\u2699\ufe0f Using PrismMind integration: {doc_pipeline.use_prismmind}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For demo purposes, let's create mock embeddings\n",
        "import numpy as np\n",
        "\n",
        "def create_mock_embedding(text: str, dim: int = 384) -> list:\n",
        "    \"\"\"Create a mock embedding based on text hash for demo purposes.\"\"\"\n",
        "    # Use hash of text to create reproducible \"embedding\"\n",
        "    hash_val = hash(text) % (2**31)\n",
        "    np.random.seed(hash_val)\n",
        "    return np.random.normal(0, 1, dim).tolist()\n",
        "\n",
        "# Process documents to create embeddings\n",
        "vector_storage = FFVectorStorageManager(config)\n",
        "\n",
        "for doc_id, document in stored_docs:\n",
        "    # Simple chunking - split by paragraphs\n",
        "    chunks = [chunk.strip() for chunk in document.content.split('\\n\\n') if chunk.strip()]\n",
        "    \n",
        "    # Create mock embeddings for each chunk\n",
        "    embeddings = [create_mock_embedding(chunk) for chunk in chunks]\n",
        "    \n",
        "    # Store vectors\n",
        "    success = await vector_storage.store_vectors(\n",
        "        session_id=alice_session.session_id,\n",
        "        document_id=doc_id,\n",
        "        chunks=chunks,\n",
        "        vectors=embeddings,\n",
        "        metadata={\"document_name\": document.filename}\n",
        "    )\n",
        "    \n",
        "    print(f\"\ud83d\udd22 Created {len(embeddings)} embeddings for {document.filename}\")\n",
        "    print(f\"\ud83d\udcca Vector storage success: {success}\")\n",
        "\n",
        "print(\"\\n\u2705 Vector embeddings created and stored!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Searching and Retrieval\n",
        "\n",
        "Now let's demonstrate the search capabilities - both text-based and vector-based search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize search engine\n",
        "search_engine = FFSearchManager(config)\n",
        "\n",
        "print(\"\ud83d\udd0d FFSearchManager initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text-based search in messages using updated DTO classes\n",
        "text_query = FFSearchQueryDTO(\n",
        "    query_text=\"data preprocessing\",\n",
        "    user_id=\"alice\",\n",
        "    session_id=alice_session.session_id,\n",
        "    include_messages=True,\n",
        "    include_documents=True\n",
        ")\n",
        "\n",
        "text_results = await search_engine.search(text_query)\n",
        "\n",
        "print(f\"\ud83d\udcdd Text Search Results for 'data preprocessing':\")\n",
        "print(f\"Found {len(text_results.results)} results\")\n",
        "for i, result in enumerate(text_results.results[:3]):  # Show first 3\n",
        "    print(f\"\\n{i+1}. Type: {result.result_type}\")\n",
        "    print(f\"   Score: {result.score:.3f}\")\n",
        "    print(f\"   Content: {result.content[:100]}...\")\n",
        "    if result.metadata:\n",
        "        print(f\"   Metadata: {result.metadata}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector-based semantic search\n",
        "search_text = \"How do I handle missing values in my dataset?\"\n",
        "search_embedding = create_mock_embedding(search_text)\n",
        "\n",
        "vector_results = await vector_storage.search_similar(\n",
        "    session_id=alice_session.session_id,\n",
        "    query_vector=search_embedding,\n",
        "    top_k=5\n",
        ")\n",
        "\n",
        "print(f\"\ud83d\udd22 Vector Search Results for: '{search_text}'\")\n",
        "print(f\"Found {len(vector_results)} similar chunks\")\n",
        "\n",
        "for i, result in enumerate(vector_results):\n",
        "    print(f\"\\n{i+1}. Similarity: {result.similarity:.3f}\")\n",
        "    print(f\"   Document: {result.metadata.get('document_name', 'Unknown')}\")\n",
        "    print(f\"   Chunk: {result.text[:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Data Inspection\n",
        "\n",
        "Let's examine the file structure that was created to understand how the data is stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def print_directory_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
        "    \"\"\"Print directory tree structure.\"\"\"\n",
        "    if current_depth > max_depth:\n",
        "        return\n",
        "    \n",
        "    path = Path(path)\n",
        "    if not path.exists():\n",
        "        return\n",
        "    \n",
        "    items = list(path.iterdir())\n",
        "    items.sort(key=lambda x: (x.is_file(), x.name))\n",
        "    \n",
        "    for i, item in enumerate(items):\n",
        "        is_last = i == len(items) - 1\n",
        "        current_prefix = \"\u2514\u2500\u2500 \" if is_last else \"\u251c\u2500\u2500 \"\n",
        "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
        "        \n",
        "        if item.is_dir() and current_depth < max_depth:\n",
        "            next_prefix = prefix + (\"    \" if is_last else \"\u2502   \")\n",
        "            print_directory_tree(item, next_prefix, max_depth, current_depth + 1)\n",
        "\n",
        "print(\"\ud83d\udcc1 Generated File Structure:\")\n",
        "print_directory_tree(demo_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's examine a sample message file\n",
        "messages_file = demo_data_path / \"users\" / \"alice\" / alice_session.session_id / \"messages.jsonl\"\n",
        "\n",
        "if messages_file.exists():\n",
        "    print(\"\ud83d\udcac Sample Messages File Content:\")\n",
        "    print(f\"\ud83d\udcc4 File: {messages_file}\")\n",
        "    print(\"\u2500\" * 50)\n",
        "    \n",
        "    with open(messages_file, 'r') as f:\n",
        "        lines = f.readlines()[:2]  # Show first 2 messages\n",
        "        for i, line in enumerate(lines, 1):\n",
        "            msg_data = json.loads(line)\n",
        "            print(f\"Message {i}:\")\n",
        "            print(f\"  Role: {msg_data['role']}\")\n",
        "            print(f\"  Content: {msg_data['content'][:100]}...\")\n",
        "            print(f\"  Timestamp: {msg_data['timestamp']}\")\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's examine the session metadata\n",
        "session_file = demo_data_path / \"users\" / \"alice\" / alice_session.session_id / \"session.json\"\n",
        "\n",
        "if session_file.exists():\n",
        "    print(\"\ud83d\udccb Session Metadata:\")\n",
        "    print(f\"\ud83d\udcc4 File: {session_file}\")\n",
        "    print(\"\u2500\" * 50)\n",
        "    \n",
        "    with open(session_file, 'r') as f:\n",
        "        session_data = json.load(f)\n",
        "        for key, value in session_data.items():\n",
        "            print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Configuration System Demo\n",
        "\n",
        "Let's explore both the legacy and new configuration systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New configuration system only - no legacy needed\n",
        "config_example = FFConfigurationManagerConfigDTO()\n",
        "print(\"\ud83d\udd27 New Configuration System:\")\n",
        "print(f\"  Base Path: {config_example.storage.base_path}\")\n",
        "print(f\"  Max Message Size: {config_example.storage.max_message_size_bytes} bytes\")\n",
        "print(f\"  Search Top K: {config_example.vector.search_top_k}\")\n",
        "print(f\"  File Locking: {config_example.locking.enable_file_locking}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New modular configuration system\n",
        "try:\n",
        "    from ff_class_configs.ff_configuration_manager_config import FFConfigurationManagerConfigDTO\n",
        "    \n",
        "    new_config = FFConfigurationManagerConfigDTO.from_environment(\"development\")\n",
        "    print(\"\\n\u2699\ufe0f New Modular Configuration System:\")\n",
        "    print(f\"  Environment: {new_config.environment}\")\n",
        "    print(f\"  Storage Base Path: {new_config.storage.base_path}\")\n",
        "    print(f\"  Search Default Limit: {new_config.search.default_limit}\")\n",
        "    print(f\"  Vector Embedding Provider: {new_config.vector.default_embedding_provider}\")\n",
        "    print(f\"  Document Max Size: {new_config.document.max_file_size_bytes / 1_048_576:.1f}MB\")\n",
        "    \n",
        "    # Show configuration summary\n",
        "    summary = new_config.get_summary()\n",
        "    print(\"\\n\ud83d\udcca Configuration Summary:\")\n",
        "    for domain, count in summary.items():\n",
        "        print(f\"  {domain}: {count} settings\")\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\"\\n\u26a0\ufe0f New configuration system not available: {e}\")\n",
        "except AttributeError as e:\n",
        "    print(f\"\\n\u26a0\ufe0f Configuration method not available: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Performance and Statistics\n",
        "\n",
        "Let's gather some basic statistics about our demo session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get session statistics\n",
        "session_stats = await storage_manager.get_session_stats(alice_session.session_id, \"alice\")\n",
        "\n",
        "print(\"\ud83d\udcca Session Statistics:\")\n",
        "print(f\"  Messages: {session_stats.get('message_count', 0)}\")\n",
        "print(f\"  Documents: {session_stats.get('document_count', 0)}\")\n",
        "print(f\"  Total Size: {session_stats.get('total_size_bytes', 0)} bytes\")\n",
        "print(f\"  Created: {alice_session.created_at}\")\n",
        "print(f\"  Last Updated: {session_stats.get('last_updated', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate storage usage\n",
        "import os\n",
        "\n",
        "def get_directory_size(path):\n",
        "    \"\"\"Calculate total size of directory.\"\"\"\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            file_path = os.path.join(dirpath, filename)\n",
        "            if os.path.exists(file_path):\n",
        "                total_size += os.path.getsize(file_path)\n",
        "    return total_size\n",
        "\n",
        "total_size = get_directory_size(demo_data_path)\n",
        "file_count = sum([len(files) for r, d, files in os.walk(demo_data_path)])\n",
        "\n",
        "print(f\"\ud83d\udcbe Storage Usage Summary:\")\n",
        "print(f\"  Total Size: {total_size:,} bytes ({total_size / 1024:.1f} KB)\")\n",
        "print(f\"  Total Files: {file_count}\")\n",
        "print(f\"  Average File Size: {total_size / max(file_count, 1):.1f} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Cleanup (Optional)\n",
        "\n",
        "Uncomment and run this cell if you want to clean up the demo data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to clean up demo data\n",
        "# import shutil\n",
        "# shutil.rmtree(demo_data_path, ignore_errors=True)\n",
        "# print(f\"\ud83e\uddf9 Cleaned up demo data from {demo_data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 Demo Complete!\n",
        "\n",
        "Congratulations! You've successfully explored the Flatfile Chat Database System. Here's what we demonstrated:\n",
        "\n",
        "### \u2705 Features Covered:\n",
        "- **User Management**: Created user profiles with metadata\n",
        "- **Chat Sessions**: Created sessions and stored messages\n",
        "- **Document Processing**: Added documents and created embeddings\n",
        "- **Search Capabilities**: Both text-based and vector-based search\n",
        "- **File Storage**: Examined the generated file structure\n",
        "- **Configuration**: Explored both legacy and new config systems\n",
        "- **Statistics**: Gathered usage and performance metrics\n",
        "\n",
        "### \ud83d\ude80 Next Steps:\n",
        "- Explore the CLI demo (`demo/cli_interactive_demo.py`)\n",
        "- Try the automated demo script (`demo/automated_demo_script.py`)\n",
        "- Experiment with your own data\n",
        "- Integrate PrismMind for enhanced document processing\n",
        "\n",
        "### \ud83d\udcda Key Benefits:\n",
        "- **No Database Required**: Pure file-based storage\n",
        "- **Human Readable**: JSON/JSONL files for easy inspection\n",
        "- **Scalable**: Efficient for both small and large datasets\n",
        "- **Flexible**: Configurable for different use cases\n",
        "- **Search Ready**: Built-in text and semantic search\n",
        "\n",
        "Thank you for trying the Flatfile Chat Database System! \ud83d\ude4f"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}