{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatfile Chat Database - Interactive Demo\n",
    "\n",
    "Welcome to the comprehensive demo of the Flatfile Chat Database System! This notebook will walk you through all the key features of this file-based storage solution for AI chat applications.\n",
    "\n",
    "## What you'll learn:\n",
    "- 💾 **Chat Storage**: Store messages, sessions, and user profiles\n",
    "- 📄 **Document Processing**: Add documents and create embeddings\n",
    "- 🔍 **Vector Search**: Semantic similarity search\n",
    "- 🔎 **Advanced Search**: Text-based search with filters\n",
    "- ⚙️ **Configuration**: Both legacy and new architecture\n",
    "- 🧠 **PrismMind Integration**: Enhanced document processing\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added PrismMind path: /home/markly2/prismmind\n",
      "✅ All imports successful\\!\n",
      "📁 Working directory: /home/markly2/claude_code/flatfile_chat_database_v2/demo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Add parent directory to path to import the flatfile database\n",
    "sys.path.append('..')\n",
    "\n",
    "# Add PrismMind directory to path (if available)\n",
    "prismmind_path = '/home/markly2/prismmind'\n",
    "if os.path.exists(prismmind_path):\n",
    "    sys.path.append(prismmind_path)\n",
    "    print(f\"✅ Added PrismMind path: {prismmind_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ PrismMind not found at: {prismmind_path}\")\n",
    "\n",
    "# Import the main components - NO LEGACY ADAPTER\n",
    "from ff_storage_manager import FFStorageManager\n",
    "from ff_class_configs.ff_configuration_manager_config import FFConfigurationManagerConfigDTO, load_config\n",
    "from ff_class_configs.ff_chat_entities_config import (\n",
    "    FFMessageDTO, FFSessionDTO, FFDocumentDTO, FFUserProfileDTO, MessageRole\n",
    ")\n",
    "from ff_search_manager import FFSearchManager, FFSearchQueryDTO\n",
    "from ff_vector_storage_manager import FFVectorStorageManager\n",
    "from ff_document_processing_manager import FFDocumentProcessingManager\n",
    "\n",
    "print(\"✅ All imports successful\\!\")\n",
    "print(f\"📁 Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Setup\n",
    "\n",
    "Let's configure the database for our demo. We'll use a temporary directory to avoid interfering with any existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📍 Demo data will be stored in: demo_data\n",
      "🔒 File locking enabled: True\n",
      "📊 Compression enabled: False\n"
     ]
    }
   ],
   "source": [
    "# Create a demo configuration using the new configuration system\n",
    "demo_data_path = Path(\"./demo_data\")\n",
    "demo_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize configuration using the new system\n",
    "config = FFConfigurationManagerConfigDTO()\n",
    "config.storage.base_path = str(demo_data_path)\n",
    "config.storage.enable_compression = False  # Disable for easier inspection\n",
    "config.locking.enable_file_locking = True\n",
    "\n",
    "print(f\"📍 Demo data will be stored in: {config.storage.base_path}\")\n",
    "print(f\"🔒 File locking enabled: {config.locking.enable_file_locking}\")\n",
    "print(f\"📊 Compression enabled: {config.storage.enable_compression}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Storage Manager\n",
    "\n",
    "The `FFStorageManager` is the main interface for all database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FFStorageManager initialized successfully!\n",
      "🏠 Base path: demo_data\n",
      "🔧 Backend type: FFFlatfileStorageBackend\n"
     ]
    }
   ],
   "source": [
    "# Initialize the storage manager\n",
    "storage_manager = FFStorageManager(config)\n",
    "\n",
    "print(\"✅ FFStorageManager initialized successfully!\")\n",
    "print(f\"🏠 Base path: {storage_manager.config.storage.base_path}\")\n",
    "print(f\"🔧 Backend type: {type(storage_manager.backend).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Management\n",
    "\n",
    "Let's create some demo users and profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 Created user: Alice Johnson (alice)\n",
      "👤 Created user: Bob Smith (bob)\n",
      "\n",
      "✅ All users created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create demo users with updated DTO classes\n",
    "users = [\n",
    "    {\n",
    "        \"user_id\": \"alice\",\n",
    "        \"profile\": FFUserProfileDTO(\n",
    "            user_id=\"alice\",\n",
    "            username=\"Alice Johnson\",\n",
    "            preferences={\"theme\": \"dark\", \"language\": \"en\"},\n",
    "            metadata={\"role\": \"data_scientist\", \"department\": \"AI Research\"}\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"user_id\": \"bob\",\n",
    "        \"profile\": FFUserProfileDTO(\n",
    "            user_id=\"bob\",\n",
    "            username=\"Bob Smith\",\n",
    "            preferences={\"theme\": \"light\", \"language\": \"en\"},\n",
    "            metadata={\"role\": \"developer\", \"department\": \"Engineering\"}\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Store user profiles\n",
    "for user in users:\n",
    "    await storage_manager.store_user_profile(user[\"profile\"])\n",
    "    print(f\"👤 Created user: {user['profile'].username} ({user['user_id']})\")\n",
    "\n",
    "print(\"\\n✅ All users created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chat Sessions and Messages\n",
    "\n",
    "Now let's create some chat sessions and add messages to demonstrate the core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💬 Created session: AI Research Discussion\n",
      "🆔 Session ID: chat_session_20250731_173523_044126\n",
      "📅 Created at: 2025-07-31T17:35:23.044133\n"
     ]
    }
   ],
   "source": [
    "# Create a chat session for Alice\n",
    "alice_session_id = await storage_manager.create_session(\n",
    "    user_id=\"alice\",\n",
    "    title=\"AI Research Discussion\"\n",
    ")\n",
    "alice_session = await storage_manager.get_session(\"alice\", alice_session_id)\n",
    "\n",
    "\n",
    "print(f\"💬 Created session: {alice_session.title}\")\n",
    "print(f\"🆔 Session ID: {alice_session.session_id}\")\n",
    "print(f\"📅 Created at: {alice_session.created_at}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Document Processing and RAG Pipeline\n",
    "\n",
    "Let's add some documents to our session and process them for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents using updated DTO classes\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"filename\": \"machine_learning_guide.md\",\n",
    "        \"content\": \"\"\"# Machine Learning Guide\n",
    "\n",
    "## Data Preprocessing\n",
    "Data preprocessing is a crucial step in machine learning that involves cleaning and transforming raw data into a format suitable for modeling.\n",
    "\n",
    "### Handling Missing Values\n",
    "- **Numerical data**: Use mean, median, or mode imputation\n",
    "- **Categorical data**: Use most frequent category or create a separate 'missing' category\n",
    "- **Advanced methods**: KNN imputation, iterative imputation\n",
    "\n",
    "### Feature Scaling\n",
    "Feature scaling ensures all features contribute equally to the model:\n",
    "- **StandardScaler**: Scales features to have mean=0 and std=1\n",
    "- **MinMaxScaler**: Scales features to a fixed range (usually 0-1)\n",
    "- **RobustScaler**: Uses median and IQR, robust to outliers\n",
    "\n",
    "### Encoding Categorical Variables\n",
    "- **One-hot encoding**: Creates binary columns for each category\n",
    "- **Label encoding**: Assigns numerical values to categories\n",
    "- **Target encoding**: Uses target variable statistics\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"filename\": \"deep_learning_basics.md\",\n",
    "        \"content\": \"\"\"# Deep Learning Basics\n",
    "\n",
    "## Neural Networks\n",
    "Neural networks are computing systems inspired by biological neural networks. They consist of layers of interconnected nodes (neurons).\n",
    "\n",
    "### Architecture Components\n",
    "- **Input Layer**: Receives the input data\n",
    "- **Hidden Layers**: Process the data through weighted connections\n",
    "- **Output Layer**: Produces the final prediction\n",
    "\n",
    "### Activation Functions\n",
    "- **ReLU**: Rectified Linear Unit, most commonly used\n",
    "- **Sigmoid**: Outputs values between 0 and 1\n",
    "- **Tanh**: Outputs values between -1 and 1\n",
    "- **Softmax**: Used in multi-class classification\n",
    "\n",
    "### Training Process\n",
    "1. **Forward Pass**: Input data flows through the network\n",
    "2. **Loss Calculation**: Compare prediction with actual target\n",
    "3. **Backward Pass**: Calculate gradients using backpropagation\n",
    "4. **Weight Update**: Adjust weights using optimization algorithm\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Store documents in the session using updated DTO classes\n",
    "stored_docs = []\n",
    "for doc_data in sample_documents:\n",
    "    # Create document object\n",
    "    document = FFDocumentDTO(\n",
    "        filename=doc_data[\"filename\"],\n",
    "        content=doc_data[\"content\"],\n",
    "        metadata={\"type\": \"markdown\", \"topic\": \"machine_learning\"}\n",
    "    )\n",
    "    \n",
    "    # Store document\n",
    "    doc_id = await storage_manager.store_document(\n",
    "        alice_session.session_id, \n",
    "        \"alice\", \n",
    "        document\n",
    "    )\n",
    "    stored_docs.append((doc_id, document))\n",
    "    print(f\"📄 Stored document: {document.filename} (ID: {doc_id})\")\n",
    "\n",
    "print(\"\\n✅ All documents stored successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vector Storage and Embeddings\n",
    "\n",
    "Let's process our documents to create embeddings for semantic search. Note: This demo uses mock embeddings for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize document pipeline\n",
    "doc_pipeline = FFDocumentProcessingManager(config)\n",
    "\n",
    "print(\"🧠 FFDocumentProcessingManager initialized\")\n",
    "print(f\"⚙️ Using PrismMind integration: {doc_pipeline.use_prismmind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo purposes, let's create mock embeddings\n",
    "import numpy as np\n",
    "\n",
    "def create_mock_embedding(text: str, dim: int = 384) -> list:\n",
    "    \"\"\"Create a mock embedding based on text hash for demo purposes.\"\"\"\n",
    "    # Use hash of text to create reproducible \"embedding\"\n",
    "    hash_val = hash(text) % (2**31)\n",
    "    np.random.seed(hash_val)\n",
    "    return np.random.normal(0, 1, dim).tolist()\n",
    "\n",
    "# Process documents to create embeddings\n",
    "vector_storage = FFVectorStorageManager(config)\n",
    "\n",
    "for doc_id, document in stored_docs:\n",
    "    # Simple chunking - split by paragraphs\n",
    "    chunks = [chunk.strip() for chunk in document.content.split('\\n\\n') if chunk.strip()]\n",
    "    \n",
    "    # Create mock embeddings for each chunk\n",
    "    embeddings = [create_mock_embedding(chunk) for chunk in chunks]\n",
    "    \n",
    "    # Store vectors\n",
    "    success = await vector_storage.store_vectors(\n",
    "        session_id=alice_session.session_id,\n",
    "        document_id=doc_id,\n",
    "        chunks=chunks,\n",
    "        vectors=embeddings,\n",
    "        metadata={\"document_name\": document.filename}\n",
    "    )\n",
    "    \n",
    "    print(f\"🔢 Created {len(embeddings)} embeddings for {document.filename}\")\n",
    "    print(f\"📊 Vector storage success: {success}\")\n",
    "\n",
    "print(\"\\n✅ Vector embeddings created and stored!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Searching and Retrieval\n",
    "\n",
    "Now let's demonstrate the search capabilities - both text-based and vector-based search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize search engine\n",
    "search_engine = FFSearchManager(config)\n",
    "\n",
    "print(\"🔍 FFSearchManager initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-based search in messages using updated DTO classes\n",
    "text_query = FFSearchQueryDTO(\n",
    "    query_text=\"data preprocessing\",\n",
    "    user_id=\"alice\",\n",
    "    session_id=alice_session.session_id,\n",
    "    include_messages=True,\n",
    "    include_documents=True\n",
    ")\n",
    "\n",
    "text_results = await search_engine.search(text_query)\n",
    "\n",
    "print(f\"📝 Text Search Results for 'data preprocessing':\")\n",
    "print(f\"Found {len(text_results.results)} results\")\n",
    "for i, result in enumerate(text_results.results[:3]):  # Show first 3\n",
    "    print(f\"\\n{i+1}. Type: {result.result_type}\")\n",
    "    print(f\"   Score: {result.score:.3f}\")\n",
    "    print(f\"   Content: {result.content[:100]}...\")\n",
    "    if result.metadata:\n",
    "        print(f\"   Metadata: {result.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector-based semantic search\n",
    "search_text = \"How do I handle missing values in my dataset?\"\n",
    "search_embedding = create_mock_embedding(search_text)\n",
    "\n",
    "vector_results = await vector_storage.search_similar(\n",
    "    session_id=alice_session.session_id,\n",
    "    query_vector=search_embedding,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"🔢 Vector Search Results for: '{search_text}'\")\n",
    "print(f\"Found {len(vector_results)} similar chunks\")\n",
    "\n",
    "for i, result in enumerate(vector_results):\n",
    "    print(f\"\\n{i+1}. Similarity: {result.similarity:.3f}\")\n",
    "    print(f\"   Document: {result.metadata.get('document_name', 'Unknown')}\")\n",
    "    print(f\"   Chunk: {result.text[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Inspection\n",
    "\n",
    "Let's examine the file structure that was created to understand how the data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_directory_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"Print directory tree structure.\"\"\"\n",
    "    if current_depth > max_depth:\n",
    "        return\n",
    "    \n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return\n",
    "    \n",
    "    items = list(path.iterdir())\n",
    "    items.sort(key=lambda x: (x.is_file(), x.name))\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        is_last = i == len(items) - 1\n",
    "        current_prefix = \"└── \" if is_last else \"├── \"\n",
    "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
    "        \n",
    "        if item.is_dir() and current_depth < max_depth:\n",
    "            next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "            print_directory_tree(item, next_prefix, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"📁 Generated File Structure:\")\n",
    "print_directory_tree(demo_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine a sample message file\n",
    "messages_file = demo_data_path / \"users\" / \"alice\" / alice_session.session_id / \"messages.jsonl\"\n",
    "\n",
    "if messages_file.exists():\n",
    "    print(\"💬 Sample Messages File Content:\")\n",
    "    print(f\"📄 File: {messages_file}\")\n",
    "    print(\"─\" * 50)\n",
    "    \n",
    "    with open(messages_file, 'r') as f:\n",
    "        lines = f.readlines()[:2]  # Show first 2 messages\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            msg_data = json.loads(line)\n",
    "            print(f\"Message {i}:\")\n",
    "            print(f\"  Role: {msg_data['role']}\")\n",
    "            print(f\"  Content: {msg_data['content'][:100]}...\")\n",
    "            print(f\"  Timestamp: {msg_data['timestamp']}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the session metadata\n",
    "session_file = demo_data_path / \"users\" / \"alice\" / alice_session.session_id / \"session.json\"\n",
    "\n",
    "if session_file.exists():\n",
    "    print(\"📋 Session Metadata:\")\n",
    "    print(f\"📄 File: {session_file}\")\n",
    "    print(\"─\" * 50)\n",
    "    \n",
    "    with open(session_file, 'r') as f:\n",
    "        session_data = json.load(f)\n",
    "        for key, value in session_data.items():\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Configuration System Demo\n",
    "\n",
    "Let's explore both the legacy and new configuration systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New configuration system only - no legacy needed\n",
    "config_example = FFConfigurationManagerConfigDTO()\n",
    "print(\"🔧 New Configuration System:\")\n",
    "print(f\"  Base Path: {config_example.storage.base_path}\")\n",
    "print(f\"  Max Message Size: {config_example.storage.max_message_size_bytes} bytes\")\n",
    "print(f\"  Search Top K: {config_example.vector.search_top_k}\")\n",
    "print(f\"  File Locking: {config_example.locking.enable_file_locking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New modular configuration system\n",
    "try:\n",
    "    from ff_class_configs.ff_configuration_manager_config import FFConfigurationManagerConfigDTO\n",
    "    \n",
    "    new_config = FFConfigurationManagerConfigDTO.from_environment(\"development\")\n",
    "    print(\"\\n⚙️ New Modular Configuration System:\")\n",
    "    print(f\"  Environment: {new_config.environment}\")\n",
    "    print(f\"  Storage Base Path: {new_config.storage.base_path}\")\n",
    "    print(f\"  Search Default Limit: {new_config.search.default_limit}\")\n",
    "    print(f\"  Vector Embedding Provider: {new_config.vector.default_embedding_provider}\")\n",
    "    print(f\"  Document Max Size: {new_config.document.max_file_size_bytes / 1_048_576:.1f}MB\")\n",
    "    \n",
    "    # Show configuration summary\n",
    "    summary = new_config.get_summary()\n",
    "    print(\"\\n📊 Configuration Summary:\")\n",
    "    for domain, count in summary.items():\n",
    "        print(f\"  {domain}: {count} settings\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"\\n⚠️ New configuration system not available: {e}\")\n",
    "except AttributeError as e:\n",
    "    print(f\"\\n⚠️ Configuration method not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance and Statistics\n",
    "\n",
    "Let's gather some basic statistics about our demo session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get session statistics\n",
    "session_stats = await storage_manager.get_session_stats(alice_session.session_id, \"alice\")\n",
    "\n",
    "print(\"📊 Session Statistics:\")\n",
    "print(f\"  Messages: {session_stats.get('message_count', 0)}\")\n",
    "print(f\"  Documents: {session_stats.get('document_count', 0)}\")\n",
    "print(f\"  Total Size: {session_stats.get('total_size_bytes', 0)} bytes\")\n",
    "print(f\"  Created: {alice_session.created_at}\")\n",
    "print(f\"  Last Updated: {session_stats.get('last_updated', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate storage usage\n",
    "import os\n",
    "\n",
    "def get_directory_size(path):\n",
    "    \"\"\"Calculate total size of directory.\"\"\"\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            if os.path.exists(file_path):\n",
    "                total_size += os.path.getsize(file_path)\n",
    "    return total_size\n",
    "\n",
    "total_size = get_directory_size(demo_data_path)\n",
    "file_count = sum([len(files) for r, d, files in os.walk(demo_data_path)])\n",
    "\n",
    "print(f\"💾 Storage Usage Summary:\")\n",
    "print(f\"  Total Size: {total_size:,} bytes ({total_size / 1024:.1f} KB)\")\n",
    "print(f\"  Total Files: {file_count}\")\n",
    "print(f\"  Average File Size: {total_size / max(file_count, 1):.1f} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cleanup (Optional)\n",
    "\n",
    "Uncomment and run this cell if you want to clean up the demo data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up demo data\n",
    "# import shutil\n",
    "# shutil.rmtree(demo_data_path, ignore_errors=True)\n",
    "# print(f\"🧹 Cleaned up demo data from {demo_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Demo Complete!\n",
    "\n",
    "Congratulations! You've successfully explored the Flatfile Chat Database System. Here's what we demonstrated:\n",
    "\n",
    "### ✅ Features Covered:\n",
    "- **User Management**: Created user profiles with metadata\n",
    "- **Chat Sessions**: Created sessions and stored messages\n",
    "- **Document Processing**: Added documents and created embeddings\n",
    "- **Search Capabilities**: Both text-based and vector-based search\n",
    "- **File Storage**: Examined the generated file structure\n",
    "- **Configuration**: Explored both legacy and new config systems\n",
    "- **Statistics**: Gathered usage and performance metrics\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "- Explore the CLI demo (`demo/cli_interactive_demo.py`)\n",
    "- Try the automated demo script (`demo/automated_demo_script.py`)\n",
    "- Experiment with your own data\n",
    "- Integrate PrismMind for enhanced document processing\n",
    "\n",
    "### 📚 Key Benefits:\n",
    "- **No Database Required**: Pure file-based storage\n",
    "- **Human Readable**: JSON/JSONL files for easy inspection\n",
    "- **Scalable**: Efficient for both small and large datasets\n",
    "- **Flexible**: Configurable for different use cases\n",
    "- **Search Ready**: Built-in text and semantic search\n",
    "\n",
    "Thank you for trying the Flatfile Chat Database System! 🙏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
